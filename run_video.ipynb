{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20013,"status":"ok","timestamp":1702139079333,"user":{"displayName":"Liuhui Wang","userId":"04856343570218016572"},"user_tz":300},"id":"sGFJy8k2QxZD","outputId":"5abf23af-f0a0-41ae-c853-7d6ad78fb9c7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1702139079333,"user":{"displayName":"Liuhui Wang","userId":"04856343570218016572"},"user_tz":300},"id":"8rg2_komQ5_A","outputId":"81fd3cd7-4154-44da-fb76-82f9f6db542c"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks\n"]}],"source":["cd /content/drive/MyDrive/'Colab Notebooks'"]},{"cell_type":"code","source":["#@markdown #**Clone github & download models**\n","\n","!git clone https://github.com/liuhui0401/final.git\n","%cd final\n","\n","!pip install git+https://github.com/facebookresearch/segment-anything.git\n","!wget -P ./weights https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth\n","\n","# load arcface\n","!wget -P ./arcface_model https://github.com/sberbank-ai/sber-swap/releases/download/arcface/backbone.pth\n","!wget -P ./arcface_model https://github.com/sberbank-ai/sber-swap/releases/download/arcface/iresnet.py\n","\n","# load landmarks detector\n","!wget -P ./insightface_func/models/antelope https://github.com/sberbank-ai/sber-swap/releases/download/antelope/glintr100.onnx\n","!wget -P ./insightface_func/models/antelope https://github.com/sberbank-ai/sber-swap/releases/download/antelope/scrfd_10g_bnkps.onnx\n","\n","# load model itself\n","!wget -P ./weights https://github.com/sberbank-ai/sber-swap/releases/download/sber-swap-v2.0/G_unet_2blocks.pth\n","\n","# load super res model\n","!wget -P ./weights https://github.com/sberbank-ai/sber-swap/releases/download/super-res/10_net_G.pth"],"metadata":{"id":"Crr4U8h5Fz_Y"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"sL5OeF3IqBNa"},"outputs":[],"source":["#@markdown #**Install required libraries**\n","\n","!pip install mxnet-cu112\n","!pip install onnxruntime-gpu==1.12\n","!pip install insightface==0.2.1\n","!pip install kornia==0.5.4\n","!pip install dill\n","\n","!rm /usr/local/lib/python3.10/dist-packages/insightface/model_zoo/model_zoo.py #change the path to python in case you use a different version\n","!wget -P /usr/local/lib/python3.10/dist-packages/insightface/model_zoo/ https://github.com/AlexanderGroshev/insightface/releases/download/model_zoo/model_zoo.py #change the path to python in case you use a different version"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H6pX8e9JtBhW"},"outputs":[],"source":["#@markdown #**Preparation**\n","\n","import cv2\n","import torch\n","import time\n","import os\n","import numpy as np\n","\n","from utils.inference.image_processing import crop_face, get_final_image, show_images\n","from utils.inference.video_processing import read_video, get_target, get_final_video, add_audio_from_another_video, face_enhancement, smooth_landmarks\n","from utils.inference.core import model_inference\n","\n","from network.AEI_Net import AEI_Net\n","from coordinate_reg.image_infer import Handler\n","from insightface_func.face_detect_crop_multi import Face_detect_crop\n","from arcface_model.iresnet import iresnet100\n","from models.pix2pix_model import Pix2PixModel\n","from models.config_sr import TestOptions\n","from insightface.utils import face_align\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-up7FWmYtDL4"},"outputs":[],"source":["#@markdown #**Initialize models**\n","\n","app = Face_detect_crop(name='antelope', root='./insightface_func/models')\n","app.prepare(ctx_id= 0, det_thresh=0.6, det_size=(640,640))\n","\n","# main model for generation\n","G = AEI_Net(backbone='unet', num_blocks=2, c_id=512)\n","G.eval()\n","G.load_state_dict(torch.load('weights/G_unet_2blocks.pth', map_location=torch.device('cpu')))\n","G = G.cuda()\n","G = G.half()\n","\n","# arcface model to get face embedding\n","netArc = iresnet100(fp16=False)\n","netArc.load_state_dict(torch.load('arcface_model/backbone.pth'))\n","netArc=netArc.cuda()\n","netArc.eval()\n","\n","# model to get face landmarks\n","handler = Handler('./coordinate_reg/model/2d106det', 0, ctx_id=0, det_size=640)\n","\n","# model to make superres of face, set use_sr=True if you want to use super resolution or use_sr=False if you don't\n","use_sr = True\n","if use_sr:\n","    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n","    torch.backends.cudnn.benchmark = True\n","    opt = TestOptions()\n","    #opt.which_epoch ='10_7'\n","    model = Pix2PixModel(opt)\n","    model.netG.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IyqSccPfW1P2"},"outputs":[],"source":["#@markdown #**Upload video**\n","\n","target_type = 'video' #@param [\"video\", \"image\"]\n","\n","source_path = ['examples/images/beckham.jpg', 'examples/images/test2.jpg'] #@param {type:\"string\"}\n","target_path = ['examples/images/test_target1.jpg'] #@param {type:\"string\"}\n","sticker_path = ['examples/images/saihong.jpg'] #@param {type:\"string\"}\n","sticker_target_path = ['examples/images/beckham.jpg'] #@param {type:\"string\"}\n","path_to_video = 'examples/videos/nggyup.mp4' #@param {type:\"string\"}\n","mode = ['cheek'] #@param {type:\"string\"} ## eyes cheek forehead face hair nose mouth mouth_open left_eye right_eye\n","\n","OUT_VIDEO_NAME = \"examples/results/result.mp4\"\n","crop_size = 224 # don't change this"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DVpSI9jlh0zX"},"outputs":[],"source":["from utils.inference.core import model_inference_all, model_inference_all_new\n","from utils.inference.video_processing import get_final_video_all, generate_video\n","\n","source_full = []\n","for source in source_path:\n","  source_full.append(crop_face(cv2.imread(source), app, crop_size)[0][:, :, ::-1])\n","target_full = []\n","for target in target_path:\n","  target_full.append(crop_face(cv2.imread(target), app, crop_size)[0])\n","sticker_full = []\n","for sticker in sticker_path:\n","  sticker_full.append(cv2.imread(sticker))\n","sticker_target_full = []\n","for sticker_target in sticker_target_path:\n","  sticker_target_full.append(crop_face(cv2.imread(sticker_target), app, crop_size)[0])\n","\n","model_inference_all_new(full_frames,\n","            source_full,\n","            target_full,\n","            sticker_full,\n","            sticker_target_full,\n","            netArc,\n","            G,\n","            app,\n","            set_target = False,\n","            crop_size=crop_size,\n","            mode=mode,\n","            handler=handler,\n","            OUT_VIDEO_NAME=OUT_VIDEO_NAME,\n","            fps=fps)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JpX0gnzOoVmV"},"outputs":[],"source":["########   stop here!!!!!!!!!!!!!!"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1vXTpsENipTmjTMggwveCkXASwxUk270n","timestamp":1701616685559}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}